{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jyt7F_lO7B7"
   },
   "source": [
    "# Python import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5527,
     "status": "ok",
     "timestamp": 1767920806003,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "lgP-ukdKO7B9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import expand_dims\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcGtIW7JO7B_"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35167,
     "status": "ok",
     "timestamp": 1767920841174,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "caee631c",
    "outputId": "222ceb4b-8ab8-4cea-ab25-d604d8159f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5684,
     "status": "ok",
     "timestamp": 1767920846860,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "e0c4e0c3",
    "outputId": "622a41e7-3a4a-407a-cf63-b9ff0a72ea0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "# 예시: base_path = '/content/drive/MyDrive/Dacon/데이콘_비전_경진대회/'\n",
    "# 주의: 폴더 경로 끝에 '/'가 있어야 합니다. 없으면 추가해주세요.\n",
    "# train = pd.read_csv('train.csv')\n",
    "# test = pd.read_csv('test.csv')\n",
    "# sub = pd.read_csv('submission.csv')\n",
    "base_path = '/content/drive/Othercomputers/내 PC/ROKEY_2526/dacon_hidden_letters/'\n",
    "\n",
    "train = pd.read_csv(base_path + 'train.csv')\n",
    "test = pd.read_csv(base_path + 'test.csv')\n",
    "sub = pd.read_csv(base_path + 'submission.csv')\n",
    "\n",
    "print(\"데이터 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAOMlzEaO7CA"
   },
   "source": [
    "# Data Preprocessing & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1767920846922,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "ZtvpnQD8O7CB",
    "outputId": "156cdfc1-0ec6-4a86-fe10-6b3809a8447c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-73cd94cf-9c2a-42e9-b4ec-baed076fbccc\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>2044</td>\n",
       "      <td>6</td>\n",
       "      <td>V</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>2045</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>2046</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 787 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73cd94cf-9c2a-42e9-b4ec-baed076fbccc')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-73cd94cf-9c2a-42e9-b4ec-baed076fbccc button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-73cd94cf-9c2a-42e9-b4ec-baed076fbccc');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-b65073c3-7e2b-4f36-b091-3564470b4f2f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b65073c3-7e2b-4f36-b091-3564470b4f2f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-b65073c3-7e2b-4f36-b091-3564470b4f2f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_4616b805-abac-44a6-82ae-96fcabd73269\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_4616b805-abac-44a6-82ae-96fcabd73269 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('train');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "        id  digit letter  0  1  2  3  4  5  6  ...  774  775  776  777  778  \\\n",
       "0        1      5      L  1  1  1  4  3  0  0  ...    2    1    0    1    2   \n",
       "1        2      0      B  0  4  0  0  4  1  1  ...    0    3    0    1    4   \n",
       "2        3      4      L  1  1  2  2  1  1  1  ...    3    3    3    0    2   \n",
       "3        4      9      D  1  2  0  2  0  4  0  ...    3    3    2    0    1   \n",
       "4        5      6      A  3  0  2  4  0  3  0  ...    4    4    3    2    1   \n",
       "...    ...    ...    ... .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
       "2043  2044      6      V  2  4  3  4  2  4  4  ...    0    2    2    0    0   \n",
       "2044  2045      1      L  3  2  2  1  1  4  0  ...    2    3    4    2    1   \n",
       "2045  2046      9      A  4  0  4  0  2  4  4  ...    2    3    1    1    3   \n",
       "2046  2047      0      Z  2  3  3  0  3  0  4  ...    2    3    1    1    0   \n",
       "2047  2048      5      Z  4  2  2  1  3  0  0  ...    4    2    4    0    4   \n",
       "\n",
       "      779  780  781  782  783  \n",
       "0       4    4    4    3    4  \n",
       "1       1    4    2    1    2  \n",
       "2       0    3    0    2    2  \n",
       "3       4    0    0    1    1  \n",
       "4       3    4    3    1    2  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "2043    1    3    1    4    0  \n",
       "2044    2    3    4    1    1  \n",
       "2045    4    2    2    0    0  \n",
       "2046    4    1    4    3    1  \n",
       "2047    3    2    4    3    4  \n",
       "\n",
       "[2048 rows x 787 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "test"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6b033b0f-903b-4c8d-831a-5d78ab250085\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>letter</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>K</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>22524</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>22525</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>22526</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>22527</td>\n",
       "      <td>K</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>22528</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 786 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b033b0f-903b-4c8d-831a-5d78ab250085')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6b033b0f-903b-4c8d-831a-5d78ab250085 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6b033b0f-903b-4c8d-831a-5d78ab250085');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-af500e3c-7276-4a14-b89f-f590bb620866\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af500e3c-7276-4a14-b89f-f590bb620866')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-af500e3c-7276-4a14-b89f-f590bb620866 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_8a5e549d-b112-4452-bf7d-f8f1594dab10\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_8a5e549d-b112-4452-bf7d-f8f1594dab10 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('test');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          id letter  0  1  2  3  4  5  6  7  ...  774  775  776  777  778  \\\n",
       "0       2049      L  0  4  0  2  4  2  3  1  ...    2    0    4    2    2   \n",
       "1       2050      C  4  1  4  0  1  1  0  2  ...    0    3    2    4    2   \n",
       "2       2051      S  0  4  0  1  3  2  3  0  ...    1    3    2    0    3   \n",
       "3       2052      K  2  1  3  3  3  4  3  0  ...    3    0    3    2    4   \n",
       "4       2053      W  1  0  1  1  2  2  1  4  ...    4    3    1    4    0   \n",
       "...      ...    ... .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
       "20475  22524      P  1  2  1  1  0  0  0  2  ...    0    1    3    0    3   \n",
       "20476  22525      S  4  1  1  4  0  0  1  1  ...    1    3    1    0    0   \n",
       "20477  22526      B  4  2  1  3  2  1  3  0  ...    3    2    3    4    1   \n",
       "20478  22527      K  1  1  2  3  4  0  4  3  ...    2    0    0    4    3   \n",
       "20479  22528      S  2  1  0  3  0  3  3  1  ...    0    3    0    1    4   \n",
       "\n",
       "       779  780  781  782  783  \n",
       "0        4    3    4    1    4  \n",
       "1        4    2    2    1    2  \n",
       "2        2    3    0    1    4  \n",
       "3        1    0    4    4    4  \n",
       "4        2    1    2    3    4  \n",
       "...    ...  ...  ...  ...  ...  \n",
       "20475    0    4    3    1    4  \n",
       "20476    1    3    1    2    0  \n",
       "20477    0    3    3    1    1  \n",
       "20478    3    3    4    4    2  \n",
       "20479    2    0    2    2    0  \n",
       "\n",
       "[20480 rows x 786 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"sub\",\n  \"rows\": 20480,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5912,\n        \"min\": 2049,\n        \"max\": 22528,\n        \"num_unique_values\": 20480,\n        \"samples\": [\n          12472,\n          7209,\n          5980\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"digit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "sub"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a9a40fac-0a58-44fe-8457-6860676fc9e8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20475</th>\n",
       "      <td>22524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>22525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>22526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20478</th>\n",
       "      <td>22527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20479</th>\n",
       "      <td>22528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20480 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9a40fac-0a58-44fe-8457-6860676fc9e8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a9a40fac-0a58-44fe-8457-6860676fc9e8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a9a40fac-0a58-44fe-8457-6860676fc9e8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-996236f4-94df-4e8a-afb5-3503dd80c0df\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-996236f4-94df-4e8a-afb5-3503dd80c0df')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-996236f4-94df-4e8a-afb5-3503dd80c0df button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_7b9d8fe0-8281-4305-8201-bc80d3861d6c\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sub')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_7b9d8fe0-8281-4305-8201-bc80d3861d6c button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('sub');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "          id  digit\n",
       "0       2049      0\n",
       "1       2050      0\n",
       "2       2051      0\n",
       "3       2052      0\n",
       "4       2053      0\n",
       "...      ...    ...\n",
       "20475  22524      0\n",
       "20476  22525      0\n",
       "20477  22526      0\n",
       "20478  22527      0\n",
       "20479  22528      0\n",
       "\n",
       "[20480 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train,test,sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1767920846948,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "Us0j3LSAO7CC",
    "outputId": "6f443ff1-018c-481b-957b-983fdc21c7ea",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "digit\n",
       "2    233\n",
       "5    225\n",
       "6    212\n",
       "4    207\n",
       "3    205\n",
       "1    202\n",
       "9    197\n",
       "7    194\n",
       "0    191\n",
       "8    182\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distribution of label('digit')\n",
    "train['digit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1767920847012,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "_3G0GlyQO7CD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "train2 = train.drop(['id','digit','letter'], axis=1)\n",
    "test2 = test.drop(['id','letter'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1767920847023,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "nrpMugQ5O7CD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert pandas dataframe to numpy array\n",
    "train2 = train2.values\n",
    "test2 = test2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1767920847197,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "swhauwicO7CE",
    "outputId": "0c470498-7a70-489c-d58b-aa433ef189e8",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d060bdb3740>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train2[100].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1767920847198,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "OueFjUlbO7CE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# reshape\n",
    "train2 = train2.reshape(-1,28,28,1)\n",
    "test2 = test2.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1767920847233,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "gS0Ik3gbO7CE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# data normalization\n",
    "train2 = train2/255.0\n",
    "test2 = test2/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1767920847270,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "hRTGsnMbO7CE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ImageDatagenerator & data augmentation\n",
    "idg = ImageDataGenerator(height_shift_range=(-1,1),width_shift_range=(-1,1))\n",
    "idg2 = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1767920848009,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "mwZjN5YXO7CE",
    "outputId": "3df5b84f-9c5d-47e3-84a5-823242a5efb2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show augmented image data\n",
    "sample_data = train2[100].copy()\n",
    "sample = expand_dims(sample_data,0)\n",
    "sample_datagen = ImageDataGenerator(height_shift_range=(-1,1), width_shift_range=(-1,1))\n",
    "sample_generator = sample_datagen.flow(sample, batch_size=1)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "for i in range(9) :\n",
    "    plt.subplot(3,3,i+1)\n",
    "    # sample_generator.next() -> next(sample_generator) 로 수정\n",
    "    sample_batch = next(sample_generator)\n",
    "    sample_image=sample_batch[0]\n",
    "    plt.imshow(sample_image.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2aGIxVRO7CF"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1767920848012,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "jbXRUfuWO7CF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "skf = StratifiedKFold(n_splits=40, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvigxJFdO7CF"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 268792,
     "status": "ok",
     "timestamp": 1767921535308,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "v_0M2GKtO7CF",
    "outputId": "95f3cd3e-8b7d-4f44-c11d-7ec02045e028",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - acc: 0.1162 - loss: 3.1320\n",
      "Epoch 1: val_loss improved from inf to 2.35286, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 683ms/step - acc: 0.1171 - loss: 3.1083 - val_acc: 0.0962 - val_loss: 2.3529 - learning_rate: 0.0020\n",
      "Epoch 2/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.1747 - loss: 2.5452\n",
      "Epoch 2: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.1761 - loss: 2.5378 - val_acc: 0.0962 - val_loss: 2.5650 - learning_rate: 0.0020\n",
      "Epoch 3/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.1988 - loss: 2.3004\n",
      "Epoch 3: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.2019 - loss: 2.2912 - val_acc: 0.0962 - val_loss: 2.8880 - learning_rate: 0.0020\n",
      "Epoch 4/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.2791 - loss: 2.0333\n",
      "Epoch 4: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.2815 - loss: 2.0273 - val_acc: 0.0962 - val_loss: 4.4538 - learning_rate: 0.0020\n",
      "Epoch 5/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.3753 - loss: 1.7418\n",
      "Epoch 5: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.3745 - loss: 1.7428 - val_acc: 0.0962 - val_loss: 5.0267 - learning_rate: 0.0020\n",
      "Epoch 6/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.4171 - loss: 1.6771\n",
      "Epoch 6: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.4182 - loss: 1.6705 - val_acc: 0.0962 - val_loss: 5.6782 - learning_rate: 0.0020\n",
      "Epoch 7/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.4699 - loss: 1.5310\n",
      "Epoch 7: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.4710 - loss: 1.5257 - val_acc: 0.0962 - val_loss: 6.3506 - learning_rate: 0.0020\n",
      "Epoch 8/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.5297 - loss: 1.3239\n",
      "Epoch 8: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5293 - loss: 1.3271 - val_acc: 0.0962 - val_loss: 5.5810 - learning_rate: 0.0020\n",
      "Epoch 9/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.5584 - loss: 1.2684\n",
      "Epoch 9: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.5586 - loss: 1.2665 - val_acc: 0.0962 - val_loss: 6.5838 - learning_rate: 0.0020\n",
      "Epoch 10/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.5985 - loss: 1.1716\n",
      "Epoch 10: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5992 - loss: 1.1684 - val_acc: 0.0962 - val_loss: 6.0937 - learning_rate: 0.0020\n",
      "Epoch 11/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.6244 - loss: 1.0846\n",
      "Epoch 11: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.6273 - loss: 1.0762 - val_acc: 0.0962 - val_loss: 5.7814 - learning_rate: 0.0020\n",
      "Epoch 12/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.6711 - loss: 0.9617\n",
      "Epoch 12: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.6713 - loss: 0.9629 - val_acc: 0.0962 - val_loss: 5.3958 - learning_rate: 0.0020\n",
      "Epoch 13/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.6909 - loss: 0.9426\n",
      "Epoch 13: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.6929 - loss: 0.9356 - val_acc: 0.0962 - val_loss: 4.5935 - learning_rate: 0.0020\n",
      "Epoch 14/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.7323 - loss: 0.8281\n",
      "Epoch 14: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.7336 - loss: 0.8249 - val_acc: 0.0962 - val_loss: 5.8985 - learning_rate: 0.0020\n",
      "Epoch 15/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.7450 - loss: 0.7551\n",
      "Epoch 15: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.7447 - loss: 0.7566 - val_acc: 0.0962 - val_loss: 5.4084 - learning_rate: 0.0020\n",
      "Epoch 16/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.7405 - loss: 0.7389\n",
      "Epoch 16: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.7430 - loss: 0.7364 - val_acc: 0.0962 - val_loss: 4.6121 - learning_rate: 0.0020\n",
      "Epoch 17/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.7922 - loss: 0.6308\n",
      "Epoch 17: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.7908 - loss: 0.6347 - val_acc: 0.0962 - val_loss: 5.2090 - learning_rate: 0.0020\n",
      "Epoch 18/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.7981 - loss: 0.5993\n",
      "Epoch 18: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.7973 - loss: 0.6021 - val_acc: 0.0962 - val_loss: 5.4953 - learning_rate: 0.0020\n",
      "Epoch 19/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.7938 - loss: 0.6015\n",
      "Epoch 19: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.7949 - loss: 0.6009 - val_acc: 0.0962 - val_loss: 5.4725 - learning_rate: 0.0020\n",
      "Epoch 20/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.7867 - loss: 0.6399\n",
      "Epoch 20: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.7876 - loss: 0.6377 - val_acc: 0.0962 - val_loss: 5.5880 - learning_rate: 0.0020\n",
      "Epoch 21/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8157 - loss: 0.5178\n",
      "Epoch 21: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8152 - loss: 0.5193 - val_acc: 0.0962 - val_loss: 5.4028 - learning_rate: 0.0020\n",
      "Epoch 22/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8276 - loss: 0.4798\n",
      "Epoch 22: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8274 - loss: 0.4828 - val_acc: 0.0962 - val_loss: 5.8187 - learning_rate: 0.0020\n",
      "Epoch 23/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8188 - loss: 0.5220\n",
      "Epoch 23: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8206 - loss: 0.5178 - val_acc: 0.0962 - val_loss: 6.5094 - learning_rate: 0.0020\n",
      "Epoch 24/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8666 - loss: 0.4293\n",
      "Epoch 24: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8646 - loss: 0.4336 - val_acc: 0.0962 - val_loss: 5.9825 - learning_rate: 0.0020\n",
      "Epoch 25/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8766 - loss: 0.4205\n",
      "Epoch 25: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8752 - loss: 0.4222 - val_acc: 0.0962 - val_loss: 4.7424 - learning_rate: 0.0020\n",
      "Epoch 26/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8604 - loss: 0.4337\n",
      "Epoch 26: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8602 - loss: 0.4317 - val_acc: 0.0962 - val_loss: 5.9456 - learning_rate: 0.0020\n",
      "Epoch 27/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8733 - loss: 0.3956\n",
      "Epoch 27: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8723 - loss: 0.3986 - val_acc: 0.1346 - val_loss: 4.4509 - learning_rate: 0.0020\n",
      "Epoch 28/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8546 - loss: 0.4018\n",
      "Epoch 28: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8549 - loss: 0.4011 - val_acc: 0.0962 - val_loss: 4.3196 - learning_rate: 0.0020\n",
      "Epoch 29/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8883 - loss: 0.3467\n",
      "Epoch 29: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.8878 - loss: 0.3481 - val_acc: 0.1538 - val_loss: 4.5955 - learning_rate: 0.0020\n",
      "Epoch 30/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8586 - loss: 0.3938\n",
      "Epoch 30: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8587 - loss: 0.3938 - val_acc: 0.1154 - val_loss: 4.7060 - learning_rate: 0.0020\n",
      "Epoch 31/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8737 - loss: 0.3896\n",
      "Epoch 31: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8743 - loss: 0.3889 - val_acc: 0.0962 - val_loss: 4.5412 - learning_rate: 0.0020\n",
      "Epoch 32/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8871 - loss: 0.3448\n",
      "Epoch 32: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8864 - loss: 0.3463 - val_acc: 0.1154 - val_loss: 4.7139 - learning_rate: 0.0020\n",
      "Epoch 33/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8873 - loss: 0.3411\n",
      "Epoch 33: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8871 - loss: 0.3418 - val_acc: 0.1154 - val_loss: 4.2961 - learning_rate: 0.0020\n",
      "Epoch 34/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9090 - loss: 0.2904\n",
      "Epoch 34: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9076 - loss: 0.2951 - val_acc: 0.1154 - val_loss: 4.9156 - learning_rate: 0.0020\n",
      "Epoch 35/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8801 - loss: 0.3791\n",
      "Epoch 35: val_loss did not improve from 2.35286\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8819 - loss: 0.3731 - val_acc: 0.1346 - val_loss: 5.0714 - learning_rate: 0.0020\n",
      "Epoch 36/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9060 - loss: 0.2769\n",
      "Epoch 36: val_loss improved from 2.35286 to 2.18792, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9058 - loss: 0.2776 - val_acc: 0.5000 - val_loss: 2.1879 - learning_rate: 0.0020\n",
      "Epoch 37/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9281 - loss: 0.2567\n",
      "Epoch 37: val_loss did not improve from 2.18792\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9264 - loss: 0.2586 - val_acc: 0.2308 - val_loss: 3.5985 - learning_rate: 0.0020\n",
      "Epoch 38/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8936 - loss: 0.2954\n",
      "Epoch 38: val_loss did not improve from 2.18792\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8943 - loss: 0.2950 - val_acc: 0.3462 - val_loss: 2.8520 - learning_rate: 0.0020\n",
      "Epoch 39/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9191 - loss: 0.2509\n",
      "Epoch 39: val_loss improved from 2.18792 to 1.72902, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.9176 - loss: 0.2542 - val_acc: 0.5577 - val_loss: 1.7290 - learning_rate: 0.0020\n",
      "Epoch 40/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8923 - loss: 0.2958\n",
      "Epoch 40: val_loss improved from 1.72902 to 0.89897, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.8925 - loss: 0.2954 - val_acc: 0.7308 - val_loss: 0.8990 - learning_rate: 0.0020\n",
      "Epoch 41/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9123 - loss: 0.2913\n",
      "Epoch 41: val_loss improved from 0.89897 to 0.77512, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.9124 - loss: 0.2899 - val_acc: 0.7885 - val_loss: 0.7751 - learning_rate: 0.0020\n",
      "Epoch 42/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9286 - loss: 0.2211\n",
      "Epoch 42: val_loss improved from 0.77512 to 0.64654, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9283 - loss: 0.2214 - val_acc: 0.7885 - val_loss: 0.6465 - learning_rate: 0.0020\n",
      "Epoch 43/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9254 - loss: 0.2160\n",
      "Epoch 43: val_loss did not improve from 0.64654\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9249 - loss: 0.2178 - val_acc: 0.6731 - val_loss: 1.2542 - learning_rate: 0.0020\n",
      "Epoch 44/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9393 - loss: 0.2228\n",
      "Epoch 44: val_loss improved from 0.64654 to 0.58903, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.9380 - loss: 0.2237 - val_acc: 0.8077 - val_loss: 0.5890 - learning_rate: 0.0020\n",
      "Epoch 45/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9094 - loss: 0.2286\n",
      "Epoch 45: val_loss did not improve from 0.58903\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9103 - loss: 0.2293 - val_acc: 0.7500 - val_loss: 0.9357 - learning_rate: 0.0020\n",
      "Epoch 46/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9336 - loss: 0.1830\n",
      "Epoch 46: val_loss improved from 0.58903 to 0.47301, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9334 - loss: 0.1854 - val_acc: 0.8269 - val_loss: 0.4730 - learning_rate: 0.0020\n",
      "Epoch 47/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9250 - loss: 0.2232\n",
      "Epoch 47: val_loss did not improve from 0.47301\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9247 - loss: 0.2239 - val_acc: 0.8462 - val_loss: 0.5666 - learning_rate: 0.0020\n",
      "Epoch 48/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9096 - loss: 0.2346\n",
      "Epoch 48: val_loss did not improve from 0.47301\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9111 - loss: 0.2328 - val_acc: 0.7885 - val_loss: 0.5728 - learning_rate: 0.0020\n",
      "Epoch 49/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9351 - loss: 0.1800\n",
      "Epoch 49: val_loss improved from 0.47301 to 0.40579, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - acc: 0.9344 - loss: 0.1819 - val_acc: 0.8846 - val_loss: 0.4058 - learning_rate: 0.0020\n",
      "Epoch 50/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9356 - loss: 0.1760\n",
      "Epoch 50: val_loss did not improve from 0.40579\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9343 - loss: 0.1802 - val_acc: 0.8462 - val_loss: 0.4768 - learning_rate: 0.0020\n",
      "Epoch 51/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9531 - loss: 0.1569\n",
      "Epoch 51: val_loss improved from 0.40579 to 0.37688, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.9520 - loss: 0.1590 - val_acc: 0.8654 - val_loss: 0.3769 - learning_rate: 0.0020\n",
      "Epoch 52/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9503 - loss: 0.1717\n",
      "Epoch 52: val_loss did not improve from 0.37688\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9495 - loss: 0.1726 - val_acc: 0.9038 - val_loss: 0.4209 - learning_rate: 0.0020\n",
      "Epoch 53/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9296 - loss: 0.1976\n",
      "Epoch 53: val_loss did not improve from 0.37688\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9296 - loss: 0.1969 - val_acc: 0.8846 - val_loss: 0.4344 - learning_rate: 0.0020\n",
      "Epoch 54/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9565 - loss: 0.1521\n",
      "Epoch 54: val_loss improved from 0.37688 to 0.29245, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9547 - loss: 0.1553 - val_acc: 0.9231 - val_loss: 0.2925 - learning_rate: 0.0020\n",
      "Epoch 55/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9377 - loss: 0.1767\n",
      "Epoch 55: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9372 - loss: 0.1783 - val_acc: 0.8846 - val_loss: 0.3647 - learning_rate: 0.0020\n",
      "Epoch 56/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9457 - loss: 0.1652\n",
      "Epoch 56: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9450 - loss: 0.1657 - val_acc: 0.8269 - val_loss: 0.6481 - learning_rate: 0.0020\n",
      "Epoch 57/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9403 - loss: 0.1724\n",
      "Epoch 57: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9402 - loss: 0.1727 - val_acc: 0.8462 - val_loss: 0.4954 - learning_rate: 0.0020\n",
      "Epoch 58/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9409 - loss: 0.1690\n",
      "Epoch 58: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9404 - loss: 0.1712 - val_acc: 0.8846 - val_loss: 0.5948 - learning_rate: 0.0020\n",
      "Epoch 59/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9463 - loss: 0.1587\n",
      "Epoch 59: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9468 - loss: 0.1575 - val_acc: 0.9038 - val_loss: 0.4887 - learning_rate: 0.0020\n",
      "Epoch 60/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9440 - loss: 0.1777\n",
      "Epoch 60: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9438 - loss: 0.1782 - val_acc: 0.8654 - val_loss: 0.4017 - learning_rate: 0.0020\n",
      "Epoch 61/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9471 - loss: 0.1813\n",
      "Epoch 61: val_loss did not improve from 0.29245\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9462 - loss: 0.1823 - val_acc: 0.9038 - val_loss: 0.3334 - learning_rate: 0.0020\n",
      "Epoch 62/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9595 - loss: 0.1368\n",
      "Epoch 62: val_loss improved from 0.29245 to 0.26863, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9583 - loss: 0.1390 - val_acc: 0.9423 - val_loss: 0.2686 - learning_rate: 0.0020\n",
      "Epoch 63/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9638 - loss: 0.1274\n",
      "Epoch 63: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9632 - loss: 0.1287 - val_acc: 0.8846 - val_loss: 0.4790 - learning_rate: 0.0020\n",
      "Epoch 64/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9458 - loss: 0.1601\n",
      "Epoch 64: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9462 - loss: 0.1591 - val_acc: 0.8462 - val_loss: 0.4293 - learning_rate: 0.0020\n",
      "Epoch 65/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9487 - loss: 0.1478\n",
      "Epoch 65: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9486 - loss: 0.1480 - val_acc: 0.9038 - val_loss: 0.4495 - learning_rate: 0.0020\n",
      "Epoch 66/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9575 - loss: 0.1280\n",
      "Epoch 66: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9576 - loss: 0.1275 - val_acc: 0.9038 - val_loss: 0.3268 - learning_rate: 0.0020\n",
      "Epoch 67/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9576 - loss: 0.1165\n",
      "Epoch 67: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9574 - loss: 0.1179 - val_acc: 0.9231 - val_loss: 0.4235 - learning_rate: 0.0020\n",
      "Epoch 68/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9538 - loss: 0.1297\n",
      "Epoch 68: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9537 - loss: 0.1308 - val_acc: 0.8462 - val_loss: 0.6266 - learning_rate: 0.0020\n",
      "Epoch 69/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9592 - loss: 0.1112\n",
      "Epoch 69: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9583 - loss: 0.1141 - val_acc: 0.8462 - val_loss: 0.5649 - learning_rate: 0.0020\n",
      "Epoch 70/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9532 - loss: 0.1291\n",
      "Epoch 70: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9529 - loss: 0.1304 - val_acc: 0.8654 - val_loss: 0.5622 - learning_rate: 0.0020\n",
      "Epoch 71/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9490 - loss: 0.1454\n",
      "Epoch 71: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9497 - loss: 0.1439 - val_acc: 0.8654 - val_loss: 0.4917 - learning_rate: 0.0020\n",
      "Epoch 72/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9532 - loss: 0.1423\n",
      "Epoch 72: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9544 - loss: 0.1395 - val_acc: 0.8654 - val_loss: 0.4508 - learning_rate: 0.0020\n",
      "Epoch 73/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9662 - loss: 0.1121\n",
      "Epoch 73: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9662 - loss: 0.1113 - val_acc: 0.8846 - val_loss: 0.3854 - learning_rate: 0.0020\n",
      "Epoch 74/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9618 - loss: 0.1218\n",
      "Epoch 74: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9614 - loss: 0.1232 - val_acc: 0.8846 - val_loss: 0.4539 - learning_rate: 0.0020\n",
      "Epoch 75/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9645 - loss: 0.1134\n",
      "Epoch 75: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9647 - loss: 0.1123 - val_acc: 0.9038 - val_loss: 0.3347 - learning_rate: 0.0020\n",
      "Epoch 76/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9567 - loss: 0.1273\n",
      "Epoch 76: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9566 - loss: 0.1267 - val_acc: 0.9038 - val_loss: 0.3073 - learning_rate: 0.0020\n",
      "Epoch 77/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9582 - loss: 0.1167\n",
      "Epoch 77: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9587 - loss: 0.1157 - val_acc: 0.8846 - val_loss: 0.3505 - learning_rate: 0.0020\n",
      "Epoch 78/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9619 - loss: 0.0994\n",
      "Epoch 78: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9618 - loss: 0.1010 - val_acc: 0.8846 - val_loss: 0.4374 - learning_rate: 0.0020\n",
      "Epoch 79/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9641 - loss: 0.1007\n",
      "Epoch 79: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9643 - loss: 0.1018 - val_acc: 0.8846 - val_loss: 0.3538 - learning_rate: 0.0020\n",
      "Epoch 80/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9656 - loss: 0.1009\n",
      "Epoch 80: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9651 - loss: 0.1021 - val_acc: 0.9038 - val_loss: 0.3728 - learning_rate: 0.0020\n",
      "Epoch 81/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9689 - loss: 0.1111\n",
      "Epoch 81: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9690 - loss: 0.1104 - val_acc: 0.8846 - val_loss: 0.3650 - learning_rate: 0.0020\n",
      "Epoch 82/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9701 - loss: 0.0965\n",
      "Epoch 82: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9703 - loss: 0.0954 - val_acc: 0.8654 - val_loss: 0.4519 - learning_rate: 0.0020\n",
      "Epoch 83/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9688 - loss: 0.0972\n",
      "Epoch 83: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9689 - loss: 0.0972 - val_acc: 0.8846 - val_loss: 0.4627 - learning_rate: 0.0020\n",
      "Epoch 84/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9688 - loss: 0.1176\n",
      "Epoch 84: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9690 - loss: 0.1165 - val_acc: 0.9038 - val_loss: 0.4022 - learning_rate: 0.0020\n",
      "Epoch 85/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9713 - loss: 0.0818\n",
      "Epoch 85: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9708 - loss: 0.0828 - val_acc: 0.9231 - val_loss: 0.4054 - learning_rate: 0.0020\n",
      "Epoch 86/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9726 - loss: 0.0847\n",
      "Epoch 86: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9717 - loss: 0.0860 - val_acc: 0.8654 - val_loss: 0.5422 - learning_rate: 0.0020\n",
      "Epoch 87/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9596 - loss: 0.1095\n",
      "Epoch 87: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9597 - loss: 0.1090 - val_acc: 0.8654 - val_loss: 0.7120 - learning_rate: 0.0020\n",
      "Epoch 88/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9722 - loss: 0.0995\n",
      "Epoch 88: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9719 - loss: 0.1008 - val_acc: 0.8846 - val_loss: 0.4852 - learning_rate: 0.0020\n",
      "Epoch 89/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9782 - loss: 0.0709\n",
      "Epoch 89: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9778 - loss: 0.0720 - val_acc: 0.8846 - val_loss: 0.5006 - learning_rate: 0.0020\n",
      "Epoch 90/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9812 - loss: 0.0632\n",
      "Epoch 90: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9806 - loss: 0.0644 - val_acc: 0.9038 - val_loss: 0.4461 - learning_rate: 0.0020\n",
      "Epoch 91/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9784 - loss: 0.0753\n",
      "Epoch 91: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9780 - loss: 0.0754 - val_acc: 0.9423 - val_loss: 0.3664 - learning_rate: 0.0020\n",
      "Epoch 92/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9733 - loss: 0.0815\n",
      "Epoch 92: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9733 - loss: 0.0815 - val_acc: 0.9038 - val_loss: 0.3422 - learning_rate: 0.0020\n",
      "Epoch 93/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9743 - loss: 0.0858\n",
      "Epoch 93: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9741 - loss: 0.0861 - val_acc: 0.8654 - val_loss: 0.5040 - learning_rate: 0.0020\n",
      "Epoch 94/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9755 - loss: 0.0762\n",
      "Epoch 94: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9755 - loss: 0.0764 - val_acc: 0.8846 - val_loss: 0.4461 - learning_rate: 0.0020\n",
      "Epoch 95/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9750 - loss: 0.0786\n",
      "Epoch 95: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9752 - loss: 0.0782 - val_acc: 0.9231 - val_loss: 0.4024 - learning_rate: 0.0020\n",
      "Epoch 96/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9742 - loss: 0.0703\n",
      "Epoch 96: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9744 - loss: 0.0707 - val_acc: 0.9038 - val_loss: 0.3805 - learning_rate: 0.0020\n",
      "Epoch 97/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9791 - loss: 0.0683\n",
      "Epoch 97: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9786 - loss: 0.0693 - val_acc: 0.9038 - val_loss: 0.4389 - learning_rate: 0.0020\n",
      "Epoch 98/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9835 - loss: 0.0586\n",
      "Epoch 98: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9831 - loss: 0.0591 - val_acc: 0.8654 - val_loss: 0.4314 - learning_rate: 0.0020\n",
      "Epoch 99/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9804 - loss: 0.0854\n",
      "Epoch 99: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9801 - loss: 0.0846 - val_acc: 0.9038 - val_loss: 0.4581 - learning_rate: 0.0020\n",
      "Epoch 100/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9750 - loss: 0.0754\n",
      "Epoch 100: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9751 - loss: 0.0753 - val_acc: 0.8654 - val_loss: 0.5403 - learning_rate: 0.0020\n",
      "Epoch 101/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9809 - loss: 0.0639\n",
      "Epoch 101: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9805 - loss: 0.0653 - val_acc: 0.8654 - val_loss: 0.5041 - learning_rate: 0.0020\n",
      "Epoch 102/2000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9748 - loss: 0.0825\n",
      "Epoch 102: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9747 - loss: 0.0824 - val_acc: 0.8846 - val_loss: 0.4585 - learning_rate: 0.0020\n",
      "Epoch 103/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9715 - loss: 0.0867\n",
      "Epoch 103: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9712 - loss: 0.0870 - val_acc: 0.9038 - val_loss: 0.4965 - learning_rate: 0.0020\n",
      "Epoch 104/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9735 - loss: 0.0730\n",
      "Epoch 104: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9735 - loss: 0.0747 - val_acc: 0.9038 - val_loss: 0.5782 - learning_rate: 0.0020\n",
      "Epoch 105/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9651 - loss: 0.1073\n",
      "Epoch 105: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9654 - loss: 0.1068 - val_acc: 0.8654 - val_loss: 0.6823 - learning_rate: 0.0020\n",
      "Epoch 106/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9723 - loss: 0.0811\n",
      "Epoch 106: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9723 - loss: 0.0814 - val_acc: 0.9615 - val_loss: 0.2896 - learning_rate: 0.0020\n",
      "Epoch 107/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9743 - loss: 0.0766\n",
      "Epoch 107: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9740 - loss: 0.0772 - val_acc: 0.8654 - val_loss: 0.3518 - learning_rate: 0.0020\n",
      "Epoch 108/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9771 - loss: 0.0599\n",
      "Epoch 108: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9769 - loss: 0.0607 - val_acc: 0.9231 - val_loss: 0.3200 - learning_rate: 0.0020\n",
      "Epoch 109/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9776 - loss: 0.0706\n",
      "Epoch 109: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9778 - loss: 0.0704 - val_acc: 0.8846 - val_loss: 0.4423 - learning_rate: 0.0020\n",
      "Epoch 110/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9813 - loss: 0.0576\n",
      "Epoch 110: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9807 - loss: 0.0594 - val_acc: 0.9231 - val_loss: 0.5195 - learning_rate: 0.0020\n",
      "Epoch 111/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9824 - loss: 0.0539\n",
      "Epoch 111: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9826 - loss: 0.0546 - val_acc: 0.9038 - val_loss: 0.3789 - learning_rate: 0.0020\n",
      "Epoch 112/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9815 - loss: 0.0663\n",
      "Epoch 112: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9818 - loss: 0.0658 - val_acc: 0.9231 - val_loss: 0.3278 - learning_rate: 0.0020\n",
      "Epoch 113/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9738 - loss: 0.0786\n",
      "Epoch 113: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9733 - loss: 0.0800 - val_acc: 0.9038 - val_loss: 0.3240 - learning_rate: 0.0020\n",
      "Epoch 114/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9835 - loss: 0.0593\n",
      "Epoch 114: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9833 - loss: 0.0593 - val_acc: 0.8846 - val_loss: 0.4631 - learning_rate: 0.0020\n",
      "Epoch 115/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9778 - loss: 0.0776\n",
      "Epoch 115: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9779 - loss: 0.0773 - val_acc: 0.8654 - val_loss: 0.4382 - learning_rate: 0.0020\n",
      "Epoch 116/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9825 - loss: 0.0578\n",
      "Epoch 116: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9828 - loss: 0.0576 - val_acc: 0.8654 - val_loss: 0.4382 - learning_rate: 0.0020\n",
      "Epoch 117/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9742 - loss: 0.0748\n",
      "Epoch 117: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9745 - loss: 0.0739 - val_acc: 0.9038 - val_loss: 0.4069 - learning_rate: 0.0020\n",
      "Epoch 118/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9858 - loss: 0.0555\n",
      "Epoch 118: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9849 - loss: 0.0569 - val_acc: 0.9038 - val_loss: 0.3820 - learning_rate: 0.0020\n",
      "Epoch 119/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9782 - loss: 0.0629\n",
      "Epoch 119: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9782 - loss: 0.0629 - val_acc: 0.8846 - val_loss: 0.4495 - learning_rate: 0.0020\n",
      "Epoch 120/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9810 - loss: 0.0561\n",
      "Epoch 120: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9807 - loss: 0.0567 - val_acc: 0.9038 - val_loss: 0.4383 - learning_rate: 0.0020\n",
      "Epoch 121/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9792 - loss: 0.0621\n",
      "Epoch 121: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9790 - loss: 0.0628 - val_acc: 0.9038 - val_loss: 0.3784 - learning_rate: 0.0020\n",
      "Epoch 122/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - acc: 0.9760 - loss: 0.0738\n",
      "Epoch 122: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.9763 - loss: 0.0723 - val_acc: 0.8846 - val_loss: 0.5160 - learning_rate: 0.0020\n",
      "Epoch 123/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9815 - loss: 0.0549\n",
      "Epoch 123: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9817 - loss: 0.0543 - val_acc: 0.8462 - val_loss: 0.5099 - learning_rate: 0.0020\n",
      "Epoch 124/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9848 - loss: 0.0452\n",
      "Epoch 124: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9846 - loss: 0.0460 - val_acc: 0.8846 - val_loss: 0.3928 - learning_rate: 0.0020\n",
      "Epoch 125/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9828 - loss: 0.0485\n",
      "Epoch 125: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9831 - loss: 0.0482 - val_acc: 0.9038 - val_loss: 0.3268 - learning_rate: 0.0020\n",
      "Epoch 126/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9863 - loss: 0.0420\n",
      "Epoch 126: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9860 - loss: 0.0426 - val_acc: 0.8846 - val_loss: 0.5191 - learning_rate: 0.0020\n",
      "Epoch 127/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9892 - loss: 0.0361\n",
      "Epoch 127: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9893 - loss: 0.0362 - val_acc: 0.9038 - val_loss: 0.4549 - learning_rate: 0.0020\n",
      "Epoch 128/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9783 - loss: 0.0598\n",
      "Epoch 128: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9786 - loss: 0.0588 - val_acc: 0.9231 - val_loss: 0.5271 - learning_rate: 0.0020\n",
      "Epoch 129/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9817 - loss: 0.0528\n",
      "Epoch 129: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9818 - loss: 0.0524 - val_acc: 0.8846 - val_loss: 0.4627 - learning_rate: 0.0020\n",
      "Epoch 130/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9893 - loss: 0.0346\n",
      "Epoch 130: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9886 - loss: 0.0365 - val_acc: 0.9038 - val_loss: 0.5521 - learning_rate: 0.0020\n",
      "Epoch 131/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9825 - loss: 0.0526\n",
      "Epoch 131: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9822 - loss: 0.0532 - val_acc: 0.9038 - val_loss: 0.5570 - learning_rate: 0.0020\n",
      "Epoch 132/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9889 - loss: 0.0432\n",
      "Epoch 132: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9887 - loss: 0.0434 - val_acc: 0.9038 - val_loss: 0.3896 - learning_rate: 0.0020\n",
      "Epoch 133/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9883 - loss: 0.0424\n",
      "Epoch 133: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9884 - loss: 0.0418 - val_acc: 0.8654 - val_loss: 0.5065 - learning_rate: 0.0020\n",
      "Epoch 134/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9887 - loss: 0.0418\n",
      "Epoch 134: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9883 - loss: 0.0429 - val_acc: 0.8654 - val_loss: 0.5896 - learning_rate: 0.0020\n",
      "Epoch 135/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9806 - loss: 0.0628\n",
      "Epoch 135: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9811 - loss: 0.0613 - val_acc: 0.8846 - val_loss: 0.5773 - learning_rate: 0.0020\n",
      "Epoch 136/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9835 - loss: 0.0433\n",
      "Epoch 136: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9833 - loss: 0.0439 - val_acc: 0.8846 - val_loss: 0.3852 - learning_rate: 0.0020\n",
      "Epoch 137/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9809 - loss: 0.0581\n",
      "Epoch 137: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9815 - loss: 0.0571 - val_acc: 0.8846 - val_loss: 0.4408 - learning_rate: 0.0020\n",
      "Epoch 138/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9837 - loss: 0.0559\n",
      "Epoch 138: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9836 - loss: 0.0551 - val_acc: 0.9038 - val_loss: 0.5208 - learning_rate: 0.0020\n",
      "Epoch 139/2000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9837 - loss: 0.0484\n",
      "Epoch 139: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9837 - loss: 0.0485 - val_acc: 0.9038 - val_loss: 0.6882 - learning_rate: 0.0020\n",
      "Epoch 140/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9871 - loss: 0.0493\n",
      "Epoch 140: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9864 - loss: 0.0510 - val_acc: 0.9038 - val_loss: 0.5641 - learning_rate: 0.0020\n",
      "Epoch 141/2000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9781 - loss: 0.0565\n",
      "Epoch 141: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9782 - loss: 0.0567 - val_acc: 0.8462 - val_loss: 0.7746 - learning_rate: 0.0020\n",
      "Epoch 142/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9803 - loss: 0.0621\n",
      "Epoch 142: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9802 - loss: 0.0624 - val_acc: 0.8462 - val_loss: 0.7127 - learning_rate: 0.0020\n",
      "Epoch 143/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9785 - loss: 0.0625\n",
      "Epoch 143: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9788 - loss: 0.0618 - val_acc: 0.8462 - val_loss: 0.6969 - learning_rate: 0.0020\n",
      "Epoch 144/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9813 - loss: 0.0609\n",
      "Epoch 144: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9816 - loss: 0.0597 - val_acc: 0.8654 - val_loss: 0.6229 - learning_rate: 0.0020\n",
      "Epoch 145/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9781 - loss: 0.0544\n",
      "Epoch 145: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9782 - loss: 0.0551 - val_acc: 0.8846 - val_loss: 0.6072 - learning_rate: 0.0020\n",
      "Epoch 146/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9793 - loss: 0.0559\n",
      "Epoch 146: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9794 - loss: 0.0557 - val_acc: 0.8846 - val_loss: 0.7417 - learning_rate: 0.0020\n",
      "Epoch 147/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9787 - loss: 0.0672\n",
      "Epoch 147: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9790 - loss: 0.0668 - val_acc: 0.8654 - val_loss: 0.7138 - learning_rate: 0.0020\n",
      "Epoch 148/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9790 - loss: 0.0614\n",
      "Epoch 148: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9796 - loss: 0.0603 - val_acc: 0.8654 - val_loss: 0.6594 - learning_rate: 0.0020\n",
      "Epoch 149/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9840 - loss: 0.0502\n",
      "Epoch 149: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9840 - loss: 0.0504 - val_acc: 0.9038 - val_loss: 0.5886 - learning_rate: 0.0020\n",
      "Epoch 150/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9764 - loss: 0.0726\n",
      "Epoch 150: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9763 - loss: 0.0722 - val_acc: 0.9038 - val_loss: 0.5052 - learning_rate: 0.0020\n",
      "Epoch 151/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9779 - loss: 0.0564\n",
      "Epoch 151: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9777 - loss: 0.0571 - val_acc: 0.8462 - val_loss: 0.6204 - learning_rate: 0.0020\n",
      "Epoch 152/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9781 - loss: 0.0668\n",
      "Epoch 152: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9784 - loss: 0.0668 - val_acc: 0.9231 - val_loss: 0.3529 - learning_rate: 0.0020\n",
      "Epoch 153/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9881 - loss: 0.0524\n",
      "Epoch 153: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9874 - loss: 0.0545 - val_acc: 0.9231 - val_loss: 0.4025 - learning_rate: 0.0020\n",
      "Epoch 154/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9807 - loss: 0.0644\n",
      "Epoch 154: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9807 - loss: 0.0643 - val_acc: 0.8269 - val_loss: 0.5809 - learning_rate: 0.0020\n",
      "Epoch 155/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9844 - loss: 0.0432\n",
      "Epoch 155: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9844 - loss: 0.0439 - val_acc: 0.9231 - val_loss: 0.4681 - learning_rate: 0.0020\n",
      "Epoch 156/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9809 - loss: 0.0762\n",
      "Epoch 156: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9806 - loss: 0.0757 - val_acc: 0.9038 - val_loss: 0.4705 - learning_rate: 0.0020\n",
      "Epoch 157/2000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9831 - loss: 0.0500\n",
      "Epoch 157: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9832 - loss: 0.0499 - val_acc: 0.9231 - val_loss: 0.4115 - learning_rate: 0.0020\n",
      "Epoch 158/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9818 - loss: 0.0643\n",
      "Epoch 158: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9823 - loss: 0.0616 - val_acc: 0.8462 - val_loss: 0.4890 - learning_rate: 0.0020\n",
      "Epoch 159/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9885 - loss: 0.0363\n",
      "Epoch 159: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9881 - loss: 0.0368 - val_acc: 0.9231 - val_loss: 0.4476 - learning_rate: 0.0020\n",
      "Epoch 160/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9839 - loss: 0.0516\n",
      "Epoch 160: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9839 - loss: 0.0520 - val_acc: 0.9038 - val_loss: 0.5425 - learning_rate: 0.0020\n",
      "Epoch 161/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9958 - loss: 0.0259\n",
      "Epoch 161: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9951 - loss: 0.0270 - val_acc: 0.8846 - val_loss: 0.4550 - learning_rate: 0.0020\n",
      "Epoch 162/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9823 - loss: 0.0476\n",
      "Epoch 162: val_loss did not improve from 0.26863\n",
      "\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9824 - loss: 0.0472 - val_acc: 0.9038 - val_loss: 0.4846 - learning_rate: 0.0020\n",
      "Epoch 163/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9852 - loss: 0.0410\n",
      "Epoch 163: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9850 - loss: 0.0421 - val_acc: 0.9231 - val_loss: 0.4295 - learning_rate: 0.0010\n",
      "Epoch 164/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9926 - loss: 0.0319\n",
      "Epoch 164: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9926 - loss: 0.0317 - val_acc: 0.9038 - val_loss: 0.5855 - learning_rate: 0.0010\n",
      "Epoch 165/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9935 - loss: 0.0299\n",
      "Epoch 165: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9936 - loss: 0.0295 - val_acc: 0.8846 - val_loss: 0.6941 - learning_rate: 0.0010\n",
      "Epoch 166/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9826 - loss: 0.0386\n",
      "Epoch 166: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9836 - loss: 0.0370 - val_acc: 0.9038 - val_loss: 0.6525 - learning_rate: 0.0010\n",
      "Epoch 167/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9973 - loss: 0.0123\n",
      "Epoch 167: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9971 - loss: 0.0126 - val_acc: 0.9038 - val_loss: 0.6273 - learning_rate: 0.0010\n",
      "Epoch 168/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9910 - loss: 0.0287\n",
      "Epoch 168: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9907 - loss: 0.0292 - val_acc: 0.9038 - val_loss: 0.5742 - learning_rate: 0.0010\n",
      "Epoch 169/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9934 - loss: 0.0229\n",
      "Epoch 169: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9936 - loss: 0.0226 - val_acc: 0.8846 - val_loss: 0.5965 - learning_rate: 0.0010\n",
      "Epoch 170/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9918 - loss: 0.0267\n",
      "Epoch 170: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9919 - loss: 0.0264 - val_acc: 0.9038 - val_loss: 0.5160 - learning_rate: 0.0010\n",
      "Epoch 171/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9952 - loss: 0.0193\n",
      "Epoch 171: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9951 - loss: 0.0196 - val_acc: 0.9038 - val_loss: 0.5292 - learning_rate: 0.0010\n",
      "Epoch 172/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9963 - loss: 0.0159\n",
      "Epoch 172: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9959 - loss: 0.0167 - val_acc: 0.9038 - val_loss: 0.4735 - learning_rate: 0.0010\n",
      "Epoch 173/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9920 - loss: 0.0205\n",
      "Epoch 173: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9921 - loss: 0.0205 - val_acc: 0.9038 - val_loss: 0.5317 - learning_rate: 0.0010\n",
      "Epoch 174/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9910 - loss: 0.0228\n",
      "Epoch 174: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9913 - loss: 0.0221 - val_acc: 0.9038 - val_loss: 0.5340 - learning_rate: 0.0010\n",
      "Epoch 175/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9970 - loss: 0.0124\n",
      "Epoch 175: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9967 - loss: 0.0132 - val_acc: 0.9038 - val_loss: 0.4984 - learning_rate: 0.0010\n",
      "Epoch 176/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9968 - loss: 0.0115\n",
      "Epoch 176: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9967 - loss: 0.0117 - val_acc: 0.9038 - val_loss: 0.4684 - learning_rate: 0.0010\n",
      "Epoch 177/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9950 - loss: 0.0178\n",
      "Epoch 177: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9951 - loss: 0.0179 - val_acc: 0.9038 - val_loss: 0.4410 - learning_rate: 0.0010\n",
      "Epoch 178/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9984 - loss: 0.0099\n",
      "Epoch 178: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9981 - loss: 0.0106 - val_acc: 0.9231 - val_loss: 0.4582 - learning_rate: 0.0010\n",
      "Epoch 179/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9967 - loss: 0.0129\n",
      "Epoch 179: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9966 - loss: 0.0133 - val_acc: 0.8846 - val_loss: 0.5079 - learning_rate: 0.0010\n",
      "Epoch 180/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9990 - loss: 0.0108\n",
      "Epoch 180: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9989 - loss: 0.0111 - val_acc: 0.9038 - val_loss: 0.5075 - learning_rate: 0.0010\n",
      "Epoch 181/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9955 - loss: 0.0120\n",
      "Epoch 181: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9954 - loss: 0.0121 - val_acc: 0.9038 - val_loss: 0.5323 - learning_rate: 0.0010\n",
      "Epoch 182/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9954 - loss: 0.0163\n",
      "Epoch 182: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9955 - loss: 0.0163 - val_acc: 0.9038 - val_loss: 0.5683 - learning_rate: 0.0010\n",
      "Epoch 183/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9956 - loss: 0.0153\n",
      "Epoch 183: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9957 - loss: 0.0152 - val_acc: 0.9038 - val_loss: 0.5903 - learning_rate: 0.0010\n",
      "Epoch 184/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9981 - loss: 0.0088\n",
      "Epoch 184: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9981 - loss: 0.0093 - val_acc: 0.9231 - val_loss: 0.5753 - learning_rate: 0.0010\n",
      "Epoch 185/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9917 - loss: 0.0179\n",
      "Epoch 185: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9917 - loss: 0.0178 - val_acc: 0.8846 - val_loss: 0.5972 - learning_rate: 0.0010\n",
      "Epoch 186/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9938 - loss: 0.0195\n",
      "Epoch 186: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9939 - loss: 0.0196 - val_acc: 0.8846 - val_loss: 0.6027 - learning_rate: 0.0010\n",
      "Epoch 187/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9922 - loss: 0.0202\n",
      "Epoch 187: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9921 - loss: 0.0206 - val_acc: 0.9038 - val_loss: 0.5291 - learning_rate: 0.0010\n",
      "Epoch 188/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9964 - loss: 0.0147\n",
      "Epoch 188: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9965 - loss: 0.0146 - val_acc: 0.9231 - val_loss: 0.4898 - learning_rate: 0.0010\n",
      "Epoch 189/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9959 - loss: 0.0182\n",
      "Epoch 189: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9959 - loss: 0.0178 - val_acc: 0.9038 - val_loss: 0.5473 - learning_rate: 0.0010\n",
      "Epoch 190/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9977 - loss: 0.0120\n",
      "Epoch 190: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9975 - loss: 0.0120 - val_acc: 0.9038 - val_loss: 0.5832 - learning_rate: 0.0010\n",
      "Epoch 191/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9945 - loss: 0.0138\n",
      "Epoch 191: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9948 - loss: 0.0136 - val_acc: 0.9038 - val_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 192/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9969 - loss: 0.0135\n",
      "Epoch 192: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9968 - loss: 0.0135 - val_acc: 0.8846 - val_loss: 0.4701 - learning_rate: 0.0010\n",
      "Epoch 193/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9952 - loss: 0.0105\n",
      "Epoch 193: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9953 - loss: 0.0103 - val_acc: 0.8654 - val_loss: 0.5166 - learning_rate: 0.0010\n",
      "Epoch 194/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9922 - loss: 0.0187\n",
      "Epoch 194: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9923 - loss: 0.0185 - val_acc: 0.9038 - val_loss: 0.4934 - learning_rate: 0.0010\n",
      "Epoch 195/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9959 - loss: 0.0167\n",
      "Epoch 195: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9957 - loss: 0.0171 - val_acc: 0.9231 - val_loss: 0.4736 - learning_rate: 0.0010\n",
      "Epoch 196/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9897 - loss: 0.0263\n",
      "Epoch 196: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9898 - loss: 0.0259 - val_acc: 0.9231 - val_loss: 0.4550 - learning_rate: 0.0010\n",
      "Epoch 197/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9963 - loss: 0.0139\n",
      "Epoch 197: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9962 - loss: 0.0143 - val_acc: 0.8846 - val_loss: 0.5685 - learning_rate: 0.0010\n",
      "Epoch 198/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9901 - loss: 0.0308\n",
      "Epoch 198: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9903 - loss: 0.0301 - val_acc: 0.9038 - val_loss: 0.5124 - learning_rate: 0.0010\n",
      "Epoch 199/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9960 - loss: 0.0160\n",
      "Epoch 199: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9961 - loss: 0.0158 - val_acc: 0.9038 - val_loss: 0.4890 - learning_rate: 0.0010\n",
      "Epoch 200/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9910 - loss: 0.0267\n",
      "Epoch 200: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9911 - loss: 0.0266 - val_acc: 0.8846 - val_loss: 0.6337 - learning_rate: 0.0010\n",
      "Epoch 201/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9957 - loss: 0.0150\n",
      "Epoch 201: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9956 - loss: 0.0152 - val_acc: 0.8654 - val_loss: 0.6144 - learning_rate: 0.0010\n",
      "Epoch 202/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9973 - loss: 0.0096\n",
      "Epoch 202: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9973 - loss: 0.0096 - val_acc: 0.8846 - val_loss: 0.5845 - learning_rate: 0.0010\n",
      "Epoch 203/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9994 - loss: 0.0069\n",
      "Epoch 203: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9993 - loss: 0.0072 - val_acc: 0.8846 - val_loss: 0.5985 - learning_rate: 0.0010\n",
      "Epoch 204/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9966 - loss: 0.0115\n",
      "Epoch 204: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9964 - loss: 0.0117 - val_acc: 0.9038 - val_loss: 0.5024 - learning_rate: 0.0010\n",
      "Epoch 205/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9938 - loss: 0.0141\n",
      "Epoch 205: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9939 - loss: 0.0145 - val_acc: 0.8846 - val_loss: 0.4618 - learning_rate: 0.0010\n",
      "Epoch 206/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9935 - loss: 0.0253\n",
      "Epoch 206: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9934 - loss: 0.0255 - val_acc: 0.8654 - val_loss: 0.5718 - learning_rate: 0.0010\n",
      "Epoch 207/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9969 - loss: 0.0113\n",
      "Epoch 207: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9968 - loss: 0.0114 - val_acc: 0.9038 - val_loss: 0.5228 - learning_rate: 0.0010\n",
      "Epoch 208/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9938 - loss: 0.0196\n",
      "Epoch 208: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9939 - loss: 0.0189 - val_acc: 0.8846 - val_loss: 0.4898 - learning_rate: 0.0010\n",
      "Epoch 209/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9960 - loss: 0.0134\n",
      "Epoch 209: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9961 - loss: 0.0132 - val_acc: 0.8846 - val_loss: 0.4413 - learning_rate: 0.0010\n",
      "Epoch 210/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9973 - loss: 0.0130\n",
      "Epoch 210: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9971 - loss: 0.0132 - val_acc: 0.8846 - val_loss: 0.4191 - learning_rate: 0.0010\n",
      "Epoch 211/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9963 - loss: 0.0105\n",
      "Epoch 211: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9961 - loss: 0.0108 - val_acc: 0.9038 - val_loss: 0.4282 - learning_rate: 0.0010\n",
      "Epoch 212/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9941 - loss: 0.0180\n",
      "Epoch 212: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9943 - loss: 0.0175 - val_acc: 0.9038 - val_loss: 0.3964 - learning_rate: 0.0010\n",
      "Epoch 213/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9971 - loss: 0.0105\n",
      "Epoch 213: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9969 - loss: 0.0106 - val_acc: 0.9038 - val_loss: 0.4000 - learning_rate: 0.0010\n",
      "Epoch 214/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9978 - loss: 0.0092\n",
      "Epoch 214: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9978 - loss: 0.0092 - val_acc: 0.9231 - val_loss: 0.4213 - learning_rate: 0.0010\n",
      "Epoch 215/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9965 - loss: 0.0117\n",
      "Epoch 215: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9963 - loss: 0.0122 - val_acc: 0.9038 - val_loss: 0.3655 - learning_rate: 0.0010\n",
      "Epoch 216/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9956 - loss: 0.0139\n",
      "Epoch 216: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9955 - loss: 0.0143 - val_acc: 0.9038 - val_loss: 0.4536 - learning_rate: 0.0010\n",
      "Epoch 217/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9923 - loss: 0.0218\n",
      "Epoch 217: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9922 - loss: 0.0214 - val_acc: 0.9038 - val_loss: 0.5670 - learning_rate: 0.0010\n",
      "Epoch 218/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9938 - loss: 0.0183\n",
      "Epoch 218: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9937 - loss: 0.0191 - val_acc: 0.9038 - val_loss: 0.5319 - learning_rate: 0.0010\n",
      "Epoch 219/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9971 - loss: 0.0109\n",
      "Epoch 219: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9969 - loss: 0.0113 - val_acc: 0.9038 - val_loss: 0.5443 - learning_rate: 0.0010\n",
      "Epoch 220/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9918 - loss: 0.0262\n",
      "Epoch 220: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9922 - loss: 0.0248 - val_acc: 0.8846 - val_loss: 0.5700 - learning_rate: 0.0010\n",
      "Epoch 221/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9916 - loss: 0.0221\n",
      "Epoch 221: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9916 - loss: 0.0218 - val_acc: 0.9038 - val_loss: 0.5054 - learning_rate: 0.0010\n",
      "Epoch 222/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9941 - loss: 0.0132\n",
      "Epoch 222: val_loss did not improve from 0.26863\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9943 - loss: 0.0135 - val_acc: 0.9038 - val_loss: 0.6852 - learning_rate: 0.0010\n",
      "Epoch 222: early stopping\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "1 번째 학습을 완료했습니다.\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - acc: 0.1287 - loss: 3.0170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2.25867, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 577ms/step - acc: 0.1295 - loss: 3.0101 - val_acc: 0.1346 - val_loss: 2.2587 - learning_rate: 0.0020\n",
      "Epoch 2/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.1808 - loss: 2.5341\n",
      "Epoch 2: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.1842 - loss: 2.5203 - val_acc: 0.0962 - val_loss: 2.3985 - learning_rate: 0.0020\n",
      "Epoch 3/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.2488 - loss: 2.1668\n",
      "Epoch 3: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.2508 - loss: 2.1616 - val_acc: 0.0962 - val_loss: 2.9108 - learning_rate: 0.0020\n",
      "Epoch 4/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.2968 - loss: 1.9811\n",
      "Epoch 4: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.2978 - loss: 1.9781 - val_acc: 0.0962 - val_loss: 3.6828 - learning_rate: 0.0020\n",
      "Epoch 5/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.3489 - loss: 1.9028\n",
      "Epoch 5: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.3510 - loss: 1.8939 - val_acc: 0.0962 - val_loss: 4.8417 - learning_rate: 0.0020\n",
      "Epoch 6/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.3902 - loss: 1.6546\n",
      "Epoch 6: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.3902 - loss: 1.6554 - val_acc: 0.0962 - val_loss: 5.1352 - learning_rate: 0.0020\n",
      "Epoch 7/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.4458 - loss: 1.6091\n",
      "Epoch 7: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.4470 - loss: 1.6035 - val_acc: 0.0962 - val_loss: 5.2067 - learning_rate: 0.0020\n",
      "Epoch 8/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.4949 - loss: 1.4503\n",
      "Epoch 8: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.4946 - loss: 1.4483 - val_acc: 0.0962 - val_loss: 5.6846 - learning_rate: 0.0020\n",
      "Epoch 9/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.5500 - loss: 1.3226\n",
      "Epoch 9: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.5507 - loss: 1.3214 - val_acc: 0.0962 - val_loss: 6.1061 - learning_rate: 0.0020\n",
      "Epoch 10/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.6033 - loss: 1.1811\n",
      "Epoch 10: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.6033 - loss: 1.1778 - val_acc: 0.0962 - val_loss: 5.4513 - learning_rate: 0.0020\n",
      "Epoch 11/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.6426 - loss: 1.0487\n",
      "Epoch 11: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.6417 - loss: 1.0495 - val_acc: 0.0962 - val_loss: 4.2319 - learning_rate: 0.0020\n",
      "Epoch 12/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.6603 - loss: 1.0418\n",
      "Epoch 12: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.6619 - loss: 1.0359 - val_acc: 0.0962 - val_loss: 5.0617 - learning_rate: 0.0020\n",
      "Epoch 13/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.6881 - loss: 0.8917\n",
      "Epoch 13: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.6886 - loss: 0.8917 - val_acc: 0.0962 - val_loss: 4.7294 - learning_rate: 0.0020\n",
      "Epoch 14/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.7248 - loss: 0.8653\n",
      "Epoch 14: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.7242 - loss: 0.8639 - val_acc: 0.0962 - val_loss: 4.0399 - learning_rate: 0.0020\n",
      "Epoch 15/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.7278 - loss: 0.8171\n",
      "Epoch 15: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.7279 - loss: 0.8152 - val_acc: 0.0962 - val_loss: 4.3782 - learning_rate: 0.0020\n",
      "Epoch 16/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.7695 - loss: 0.7401\n",
      "Epoch 16: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.7684 - loss: 0.7398 - val_acc: 0.0962 - val_loss: 5.6244 - learning_rate: 0.0020\n",
      "Epoch 17/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.7558 - loss: 0.7148\n",
      "Epoch 17: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.7561 - loss: 0.7143 - val_acc: 0.0962 - val_loss: 4.6040 - learning_rate: 0.0020\n",
      "Epoch 18/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.7863 - loss: 0.6475\n",
      "Epoch 18: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.7862 - loss: 0.6479 - val_acc: 0.0962 - val_loss: 4.5449 - learning_rate: 0.0020\n",
      "Epoch 19/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.7963 - loss: 0.6124\n",
      "Epoch 19: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.7964 - loss: 0.6138 - val_acc: 0.0962 - val_loss: 4.3475 - learning_rate: 0.0020\n",
      "Epoch 20/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8288 - loss: 0.5584\n",
      "Epoch 20: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8277 - loss: 0.5623 - val_acc: 0.0962 - val_loss: 5.9850 - learning_rate: 0.0020\n",
      "Epoch 21/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8285 - loss: 0.5401\n",
      "Epoch 21: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8276 - loss: 0.5404 - val_acc: 0.0962 - val_loss: 4.7656 - learning_rate: 0.0020\n",
      "Epoch 22/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.8195 - loss: 0.5198\n",
      "Epoch 22: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8201 - loss: 0.5183 - val_acc: 0.0962 - val_loss: 5.1695 - learning_rate: 0.0020\n",
      "Epoch 23/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8291 - loss: 0.5117\n",
      "Epoch 23: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.8288 - loss: 0.5118 - val_acc: 0.0962 - val_loss: 5.8436 - learning_rate: 0.0020\n",
      "Epoch 24/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8446 - loss: 0.4604\n",
      "Epoch 24: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8453 - loss: 0.4586 - val_acc: 0.0962 - val_loss: 6.1801 - learning_rate: 0.0020\n",
      "Epoch 25/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8589 - loss: 0.4377\n",
      "Epoch 25: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8588 - loss: 0.4377 - val_acc: 0.0962 - val_loss: 5.6289 - learning_rate: 0.0020\n",
      "Epoch 26/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8451 - loss: 0.4537\n",
      "Epoch 26: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8460 - loss: 0.4521 - val_acc: 0.0962 - val_loss: 7.8553 - learning_rate: 0.0020\n",
      "Epoch 27/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8693 - loss: 0.4002\n",
      "Epoch 27: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8690 - loss: 0.4005 - val_acc: 0.0962 - val_loss: 6.1481 - learning_rate: 0.0020\n",
      "Epoch 28/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8730 - loss: 0.3805\n",
      "Epoch 28: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8734 - loss: 0.3817 - val_acc: 0.0962 - val_loss: 6.9032 - learning_rate: 0.0020\n",
      "Epoch 29/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8668 - loss: 0.3720\n",
      "Epoch 29: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.8670 - loss: 0.3735 - val_acc: 0.1731 - val_loss: 4.8220 - learning_rate: 0.0020\n",
      "Epoch 30/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8721 - loss: 0.3720\n",
      "Epoch 30: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8726 - loss: 0.3718 - val_acc: 0.0962 - val_loss: 5.7309 - learning_rate: 0.0020\n",
      "Epoch 31/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8789 - loss: 0.3561\n",
      "Epoch 31: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.8784 - loss: 0.3565 - val_acc: 0.0962 - val_loss: 5.9691 - learning_rate: 0.0020\n",
      "Epoch 32/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8964 - loss: 0.3311\n",
      "Epoch 32: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8966 - loss: 0.3321 - val_acc: 0.1154 - val_loss: 4.4665 - learning_rate: 0.0020\n",
      "Epoch 33/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.8788 - loss: 0.3485\n",
      "Epoch 33: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.8795 - loss: 0.3459 - val_acc: 0.3654 - val_loss: 2.8881 - learning_rate: 0.0020\n",
      "Epoch 34/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.8984 - loss: 0.3143\n",
      "Epoch 34: val_loss did not improve from 2.25867\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - acc: 0.8990 - loss: 0.3129 - val_acc: 0.3077 - val_loss: 3.2909 - learning_rate: 0.0020\n",
      "Epoch 35/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9024 - loss: 0.2850\n",
      "Epoch 35: val_loss improved from 2.25867 to 1.89641, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.9024 - loss: 0.2856 - val_acc: 0.5000 - val_loss: 1.8964 - learning_rate: 0.0020\n",
      "Epoch 36/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9132 - loss: 0.2692\n",
      "Epoch 36: val_loss did not improve from 1.89641\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9125 - loss: 0.2717 - val_acc: 0.3077 - val_loss: 3.2576 - learning_rate: 0.0020\n",
      "Epoch 37/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9146 - loss: 0.2532\n",
      "Epoch 37: val_loss did not improve from 1.89641\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9134 - loss: 0.2560 - val_acc: 0.3462 - val_loss: 2.8338 - learning_rate: 0.0020\n",
      "Epoch 38/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9045 - loss: 0.2814\n",
      "Epoch 38: val_loss did not improve from 1.89641\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9047 - loss: 0.2815 - val_acc: 0.4423 - val_loss: 2.0817 - learning_rate: 0.0020\n",
      "Epoch 39/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9280 - loss: 0.2337\n",
      "Epoch 39: val_loss improved from 1.89641 to 0.74220, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.9267 - loss: 0.2369 - val_acc: 0.7308 - val_loss: 0.7422 - learning_rate: 0.0020\n",
      "Epoch 40/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9049 - loss: 0.2952\n",
      "Epoch 40: val_loss did not improve from 0.74220\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9057 - loss: 0.2936 - val_acc: 0.5962 - val_loss: 0.9912 - learning_rate: 0.0020\n",
      "Epoch 41/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9195 - loss: 0.2292\n",
      "Epoch 41: val_loss did not improve from 0.74220\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9198 - loss: 0.2302 - val_acc: 0.7308 - val_loss: 0.8293 - learning_rate: 0.0020\n",
      "Epoch 42/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9239 - loss: 0.2188\n",
      "Epoch 42: val_loss improved from 0.74220 to 0.72732, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9238 - loss: 0.2192 - val_acc: 0.7885 - val_loss: 0.7273 - learning_rate: 0.0020\n",
      "Epoch 43/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9179 - loss: 0.2356\n",
      "Epoch 43: val_loss did not improve from 0.72732\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9185 - loss: 0.2353 - val_acc: 0.7308 - val_loss: 0.8704 - learning_rate: 0.0020\n",
      "Epoch 44/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9128 - loss: 0.2450\n",
      "Epoch 44: val_loss improved from 0.72732 to 0.50967, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9137 - loss: 0.2431 - val_acc: 0.8462 - val_loss: 0.5097 - learning_rate: 0.0020\n",
      "Epoch 45/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9360 - loss: 0.1985\n",
      "Epoch 45: val_loss did not improve from 0.50967\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9355 - loss: 0.1999 - val_acc: 0.8077 - val_loss: 0.5752 - learning_rate: 0.0020\n",
      "Epoch 46/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9279 - loss: 0.2133\n",
      "Epoch 46: val_loss did not improve from 0.50967\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9284 - loss: 0.2120 - val_acc: 0.7308 - val_loss: 0.7229 - learning_rate: 0.0020\n",
      "Epoch 47/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9176 - loss: 0.2224\n",
      "Epoch 47: val_loss improved from 0.50967 to 0.40029, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - acc: 0.9188 - loss: 0.2211 - val_acc: 0.8846 - val_loss: 0.4003 - learning_rate: 0.0020\n",
      "Epoch 48/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9311 - loss: 0.1784\n",
      "Epoch 48: val_loss did not improve from 0.40029\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9306 - loss: 0.1815 - val_acc: 0.8269 - val_loss: 0.4208 - learning_rate: 0.0020\n",
      "Epoch 49/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9364 - loss: 0.1715\n",
      "Epoch 49: val_loss did not improve from 0.40029\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9350 - loss: 0.1755 - val_acc: 0.8846 - val_loss: 0.4254 - learning_rate: 0.0020\n",
      "Epoch 50/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - acc: 0.9366 - loss: 0.2147\n",
      "Epoch 50: val_loss improved from 0.40029 to 0.31175, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - acc: 0.9367 - loss: 0.2129 - val_acc: 0.8654 - val_loss: 0.3117 - learning_rate: 0.0020\n",
      "Epoch 51/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - acc: 0.9404 - loss: 0.1782\n",
      "Epoch 51: val_loss improved from 0.31175 to 0.29635, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - acc: 0.9400 - loss: 0.1798 - val_acc: 0.8846 - val_loss: 0.2963 - learning_rate: 0.0020\n",
      "Epoch 52/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9300 - loss: 0.2029\n",
      "Epoch 52: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9298 - loss: 0.2026 - val_acc: 0.8654 - val_loss: 0.3875 - learning_rate: 0.0020\n",
      "Epoch 53/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9395 - loss: 0.1827\n",
      "Epoch 53: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9402 - loss: 0.1817 - val_acc: 0.9038 - val_loss: 0.4246 - learning_rate: 0.0020\n",
      "Epoch 54/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9402 - loss: 0.1634\n",
      "Epoch 54: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9394 - loss: 0.1669 - val_acc: 0.8654 - val_loss: 0.3674 - learning_rate: 0.0020\n",
      "Epoch 55/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9530 - loss: 0.1437\n",
      "Epoch 55: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9522 - loss: 0.1470 - val_acc: 0.8846 - val_loss: 0.3767 - learning_rate: 0.0020\n",
      "Epoch 56/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9364 - loss: 0.1992\n",
      "Epoch 56: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9368 - loss: 0.1984 - val_acc: 0.8462 - val_loss: 0.3993 - learning_rate: 0.0020\n",
      "Epoch 57/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9475 - loss: 0.1616\n",
      "Epoch 57: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9463 - loss: 0.1652 - val_acc: 0.8846 - val_loss: 0.4319 - learning_rate: 0.0020\n",
      "Epoch 58/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9347 - loss: 0.1827\n",
      "Epoch 58: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9351 - loss: 0.1827 - val_acc: 0.8077 - val_loss: 0.5888 - learning_rate: 0.0020\n",
      "Epoch 59/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9420 - loss: 0.1743\n",
      "Epoch 59: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9419 - loss: 0.1753 - val_acc: 0.8846 - val_loss: 0.3829 - learning_rate: 0.0020\n",
      "Epoch 60/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9490 - loss: 0.1554\n",
      "Epoch 60: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9490 - loss: 0.1560 - val_acc: 0.9038 - val_loss: 0.3667 - learning_rate: 0.0020\n",
      "Epoch 61/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9563 - loss: 0.1363\n",
      "Epoch 61: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9558 - loss: 0.1385 - val_acc: 0.8846 - val_loss: 0.4364 - learning_rate: 0.0020\n",
      "Epoch 62/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9576 - loss: 0.1231\n",
      "Epoch 62: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9578 - loss: 0.1232 - val_acc: 0.8846 - val_loss: 0.5239 - learning_rate: 0.0020\n",
      "Epoch 63/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9622 - loss: 0.1080\n",
      "Epoch 63: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9620 - loss: 0.1092 - val_acc: 0.8462 - val_loss: 0.4987 - learning_rate: 0.0020\n",
      "Epoch 64/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9591 - loss: 0.1222\n",
      "Epoch 64: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9584 - loss: 0.1236 - val_acc: 0.8269 - val_loss: 0.4684 - learning_rate: 0.0020\n",
      "Epoch 65/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9598 - loss: 0.1244\n",
      "Epoch 65: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9584 - loss: 0.1274 - val_acc: 0.8269 - val_loss: 0.5984 - learning_rate: 0.0020\n",
      "Epoch 66/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9509 - loss: 0.1586\n",
      "Epoch 66: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9510 - loss: 0.1585 - val_acc: 0.8846 - val_loss: 0.4515 - learning_rate: 0.0020\n",
      "Epoch 67/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9471 - loss: 0.1394\n",
      "Epoch 67: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9481 - loss: 0.1385 - val_acc: 0.8654 - val_loss: 0.3911 - learning_rate: 0.0020\n",
      "Epoch 68/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9637 - loss: 0.1027\n",
      "Epoch 68: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9636 - loss: 0.1035 - val_acc: 0.8077 - val_loss: 0.5013 - learning_rate: 0.0020\n",
      "Epoch 69/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9695 - loss: 0.0981\n",
      "Epoch 69: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9686 - loss: 0.1003 - val_acc: 0.8269 - val_loss: 0.5840 - learning_rate: 0.0020\n",
      "Epoch 70/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9587 - loss: 0.1182\n",
      "Epoch 70: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9590 - loss: 0.1188 - val_acc: 0.8846 - val_loss: 0.5260 - learning_rate: 0.0020\n",
      "Epoch 71/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9659 - loss: 0.1070\n",
      "Epoch 71: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9650 - loss: 0.1081 - val_acc: 0.8654 - val_loss: 0.4476 - learning_rate: 0.0020\n",
      "Epoch 72/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9499 - loss: 0.1415\n",
      "Epoch 72: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9500 - loss: 0.1416 - val_acc: 0.8846 - val_loss: 0.4566 - learning_rate: 0.0020\n",
      "Epoch 73/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9634 - loss: 0.1138\n",
      "Epoch 73: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9631 - loss: 0.1144 - val_acc: 0.9038 - val_loss: 0.4364 - learning_rate: 0.0020\n",
      "Epoch 74/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9509 - loss: 0.1325\n",
      "Epoch 74: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9507 - loss: 0.1335 - val_acc: 0.8846 - val_loss: 0.3818 - learning_rate: 0.0020\n",
      "Epoch 75/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9717 - loss: 0.0963\n",
      "Epoch 75: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9716 - loss: 0.0970 - val_acc: 0.8269 - val_loss: 0.6823 - learning_rate: 0.0020\n",
      "Epoch 76/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9604 - loss: 0.1298\n",
      "Epoch 76: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9609 - loss: 0.1272 - val_acc: 0.8269 - val_loss: 0.5477 - learning_rate: 0.0020\n",
      "Epoch 77/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9687 - loss: 0.0939\n",
      "Epoch 77: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9684 - loss: 0.0941 - val_acc: 0.8654 - val_loss: 0.3639 - learning_rate: 0.0020\n",
      "Epoch 78/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9575 - loss: 0.1084\n",
      "Epoch 78: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9576 - loss: 0.1088 - val_acc: 0.8846 - val_loss: 0.4451 - learning_rate: 0.0020\n",
      "Epoch 79/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9684 - loss: 0.0780\n",
      "Epoch 79: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9682 - loss: 0.0794 - val_acc: 0.8462 - val_loss: 0.5384 - learning_rate: 0.0020\n",
      "Epoch 80/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9766 - loss: 0.0775\n",
      "Epoch 80: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9765 - loss: 0.0776 - val_acc: 0.8462 - val_loss: 0.4346 - learning_rate: 0.0020\n",
      "Epoch 81/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9669 - loss: 0.0945\n",
      "Epoch 81: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9666 - loss: 0.0945 - val_acc: 0.8654 - val_loss: 0.5280 - learning_rate: 0.0020\n",
      "Epoch 82/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9629 - loss: 0.0935\n",
      "Epoch 82: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9627 - loss: 0.0950 - val_acc: 0.8846 - val_loss: 0.4160 - learning_rate: 0.0020\n",
      "Epoch 83/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9598 - loss: 0.1307\n",
      "Epoch 83: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9596 - loss: 0.1317 - val_acc: 0.8654 - val_loss: 0.4665 - learning_rate: 0.0020\n",
      "Epoch 84/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9534 - loss: 0.1195\n",
      "Epoch 84: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9540 - loss: 0.1199 - val_acc: 0.8846 - val_loss: 0.5755 - learning_rate: 0.0020\n",
      "Epoch 85/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9699 - loss: 0.0946\n",
      "Epoch 85: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9695 - loss: 0.0954 - val_acc: 0.8077 - val_loss: 0.5645 - learning_rate: 0.0020\n",
      "Epoch 86/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9645 - loss: 0.1028\n",
      "Epoch 86: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9648 - loss: 0.1028 - val_acc: 0.8846 - val_loss: 0.4273 - learning_rate: 0.0020\n",
      "Epoch 87/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - acc: 0.9727 - loss: 0.0781\n",
      "Epoch 87: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - acc: 0.9722 - loss: 0.0798 - val_acc: 0.9038 - val_loss: 0.3594 - learning_rate: 0.0020\n",
      "Epoch 88/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9637 - loss: 0.0994\n",
      "Epoch 88: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9637 - loss: 0.1004 - val_acc: 0.8654 - val_loss: 0.4812 - learning_rate: 0.0020\n",
      "Epoch 89/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9703 - loss: 0.0747\n",
      "Epoch 89: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9700 - loss: 0.0769 - val_acc: 0.8654 - val_loss: 0.4128 - learning_rate: 0.0020\n",
      "Epoch 90/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9832 - loss: 0.0717\n",
      "Epoch 90: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9826 - loss: 0.0730 - val_acc: 0.8462 - val_loss: 0.5681 - learning_rate: 0.0020\n",
      "Epoch 91/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9692 - loss: 0.0875\n",
      "Epoch 91: val_loss did not improve from 0.29635\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9692 - loss: 0.0874 - val_acc: 0.8654 - val_loss: 0.5104 - learning_rate: 0.0020\n",
      "Epoch 92/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9816 - loss: 0.0719\n",
      "Epoch 92: val_loss improved from 0.29635 to 0.29378, saving model to best_cvision.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - acc: 0.9811 - loss: 0.0729 - val_acc: 0.8654 - val_loss: 0.2938 - learning_rate: 0.0020\n",
      "Epoch 93/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9739 - loss: 0.0838\n",
      "Epoch 93: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9734 - loss: 0.0841 - val_acc: 0.8846 - val_loss: 0.3601 - learning_rate: 0.0020\n",
      "Epoch 94/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9772 - loss: 0.0717\n",
      "Epoch 94: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9770 - loss: 0.0719 - val_acc: 0.8654 - val_loss: 0.4173 - learning_rate: 0.0020\n",
      "Epoch 95/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9701 - loss: 0.0763\n",
      "Epoch 95: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9702 - loss: 0.0762 - val_acc: 0.8846 - val_loss: 0.4152 - learning_rate: 0.0020\n",
      "Epoch 96/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9697 - loss: 0.0764\n",
      "Epoch 96: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9701 - loss: 0.0763 - val_acc: 0.8846 - val_loss: 0.4969 - learning_rate: 0.0020\n",
      "Epoch 97/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9729 - loss: 0.0792\n",
      "Epoch 97: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9735 - loss: 0.0784 - val_acc: 0.8654 - val_loss: 0.4070 - learning_rate: 0.0020\n",
      "Epoch 98/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9834 - loss: 0.0631\n",
      "Epoch 98: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9827 - loss: 0.0640 - val_acc: 0.8462 - val_loss: 0.4606 - learning_rate: 0.0020\n",
      "Epoch 99/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9679 - loss: 0.0969\n",
      "Epoch 99: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9676 - loss: 0.0981 - val_acc: 0.9423 - val_loss: 0.2998 - learning_rate: 0.0020\n",
      "Epoch 100/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9720 - loss: 0.0834\n",
      "Epoch 100: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9718 - loss: 0.0836 - val_acc: 0.8462 - val_loss: 0.3724 - learning_rate: 0.0020\n",
      "Epoch 101/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9665 - loss: 0.0841\n",
      "Epoch 101: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9667 - loss: 0.0845 - val_acc: 0.8269 - val_loss: 0.6437 - learning_rate: 0.0020\n",
      "Epoch 102/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9841 - loss: 0.0638\n",
      "Epoch 102: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9830 - loss: 0.0663 - val_acc: 0.9231 - val_loss: 0.3704 - learning_rate: 0.0020\n",
      "Epoch 103/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9788 - loss: 0.0745\n",
      "Epoch 103: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9791 - loss: 0.0733 - val_acc: 0.9423 - val_loss: 0.3957 - learning_rate: 0.0020\n",
      "Epoch 104/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9774 - loss: 0.0656\n",
      "Epoch 104: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9772 - loss: 0.0667 - val_acc: 0.9038 - val_loss: 0.4000 - learning_rate: 0.0020\n",
      "Epoch 105/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9792 - loss: 0.0640\n",
      "Epoch 105: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9790 - loss: 0.0646 - val_acc: 0.8269 - val_loss: 0.5946 - learning_rate: 0.0020\n",
      "Epoch 106/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9857 - loss: 0.0508\n",
      "Epoch 106: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9856 - loss: 0.0510 - val_acc: 0.8462 - val_loss: 0.5115 - learning_rate: 0.0020\n",
      "Epoch 107/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9756 - loss: 0.0740\n",
      "Epoch 107: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9755 - loss: 0.0738 - val_acc: 0.8269 - val_loss: 0.6007 - learning_rate: 0.0020\n",
      "Epoch 108/2000\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.9828 - loss: 0.0618\n",
      "Epoch 108: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - acc: 0.9826 - loss: 0.0624 - val_acc: 0.8462 - val_loss: 0.5137 - learning_rate: 0.0020\n",
      "Epoch 109/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9726 - loss: 0.0866\n",
      "Epoch 109: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9728 - loss: 0.0860 - val_acc: 0.9038 - val_loss: 0.6014 - learning_rate: 0.0020\n",
      "Epoch 110/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9772 - loss: 0.0794\n",
      "Epoch 110: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9771 - loss: 0.0787 - val_acc: 0.8654 - val_loss: 0.4945 - learning_rate: 0.0020\n",
      "Epoch 111/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9807 - loss: 0.0651\n",
      "Epoch 111: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9803 - loss: 0.0656 - val_acc: 0.9038 - val_loss: 0.4482 - learning_rate: 0.0020\n",
      "Epoch 112/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9786 - loss: 0.0684\n",
      "Epoch 112: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9792 - loss: 0.0669 - val_acc: 0.9038 - val_loss: 0.4396 - learning_rate: 0.0020\n",
      "Epoch 113/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9816 - loss: 0.0509\n",
      "Epoch 113: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9813 - loss: 0.0516 - val_acc: 0.8846 - val_loss: 0.4152 - learning_rate: 0.0020\n",
      "Epoch 114/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9873 - loss: 0.0375\n",
      "Epoch 114: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9871 - loss: 0.0386 - val_acc: 0.8846 - val_loss: 0.3868 - learning_rate: 0.0020\n",
      "Epoch 115/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.9786 - loss: 0.0644\n",
      "Epoch 115: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - acc: 0.9791 - loss: 0.0639 - val_acc: 0.8846 - val_loss: 0.3925 - learning_rate: 0.0020\n",
      "Epoch 116/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9787 - loss: 0.0682\n",
      "Epoch 116: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - acc: 0.9786 - loss: 0.0676 - val_acc: 0.9038 - val_loss: 0.3835 - learning_rate: 0.0020\n",
      "Epoch 117/2000\n",
      "\u001b[1m15/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - acc: 0.9873 - loss: 0.0425\n",
      "Epoch 117: val_loss did not improve from 0.29378\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - acc: 0.9867 - loss: 0.0443 - val_acc: 0.9231 - val_loss: 0.3748 - learning_rate: 0.0020\n",
      "Epoch 118/2000\n",
      "\u001b[1m 3/16\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 0.9965 - loss: 0.0264"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reLR = ReduceLROnPlateau(patience=100,verbose=1,factor=0.5) #learning rate scheduler\n",
    "es = EarlyStopping(patience=160, verbose=1)\n",
    "\n",
    "val_loss_min = []\n",
    "result = 0\n",
    "nth = 0\n",
    "\n",
    "for train_index, valid_index in skf.split(train2,train['digit']) :\n",
    "\n",
    "    mc = ModelCheckpoint('best_cvision.h5',save_best_only=True, verbose=1)\n",
    "\n",
    "    x_train = train2[train_index]\n",
    "    x_valid = train2[valid_index]\n",
    "    y_train = train['digit'][train_index]\n",
    "    y_valid = train['digit'][valid_index]\n",
    "\n",
    "    train_generator = idg.flow(x_train,y_train,batch_size=8)\n",
    "    valid_generator = idg2.flow(x_valid,y_valid, batch_size=8)\n",
    "    test_generator = idg2.flow(test2,shuffle=False, batch_size=8)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer added explicitly to avoid warnings\n",
    "    model.add(Input(shape=(28,28,1)))\n",
    "    model.add(Conv2D(16,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((3,3)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(5,5),activation='relu',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((3,3)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    # Fix: lr -> learning_rate\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.002,epsilon=1e-07),metrics=['acc'])\n",
    "\n",
    "    # Fix: fit_generator -> fit\n",
    "    learning_history = model.fit(train_generator,epochs=2000, validation_data=valid_generator, callbacks=[es,mc,reLR])\n",
    "\n",
    "    # predict\n",
    "    model.load_weights('best_cvision.h5')\n",
    "    # Fix: predict_generator -> predict\n",
    "    result += model.predict(test_generator,verbose=True)/40\n",
    "\n",
    "    # save val_loss\n",
    "    hist = pd.DataFrame(learning_history.history)\n",
    "    val_loss_min.append(hist['val_loss'].min())\n",
    "\n",
    "    nth += 1\n",
    "    print(nth, '번째 학습을 완료했습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1767921061232,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "cTPKFudWO7CF",
    "outputId": "416d9681-36b9-4f43-ce0f-91eb76ec5c54",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(val_loss_min, np.mean(val_loss_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1767921061274,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "5k6hCZzaO7CF",
    "outputId": "12cfbe3f-5ccb-4693-d39a-b23afee7b960",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m25,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m25,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m25,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">859,968</span> (3.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m859,968\u001b[0m (3.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286,346</span> (1.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m286,346\u001b[0m (1.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">928</span> (3.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m928\u001b[0m (3.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">572,694</span> (2.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m572,694\u001b[0m (2.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raqSFhlXO7CF"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1767921061284,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "9MmltQ1qO7CF",
    "outputId": "9f1846c4-36b7-48b7-f590-c9e07dc66021",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'argmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2448024637.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'digit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'argmax'"
     ]
    }
   ],
   "source": [
    "sub['digit'] = result.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260865,
     "status": "aborted",
     "timestamp": 1767921061282,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "ZRCm-Ct1O7CF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260906,
     "status": "aborted",
     "timestamp": 1767921061327,
     "user": {
      "displayName": "최진우",
      "userId": "07408222835142392920"
     },
     "user_tz": -540
    },
    "id": "KGmO-6W-O7CF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('Dacon_cvision_0914_40_epsNone.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
